{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984009b3",
   "metadata": {},
   "source": [
    "# Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4b1a9",
   "metadata": {},
   "source": [
    "## Union and Intersection (non-conditional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5857af90",
   "metadata": {},
   "source": [
    "$ P(A \\cup B) = P(A) + P(B) $\n",
    "\n",
    "Likewise, this can be extended to any number of unions.<br>\n",
    "$P(A_1 \\cup A_2 \\cup \\dotsc \\cup A_n) = P(A_1) + P(A_2) + \\dotsc + P(A_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73256c66",
   "metadata": {},
   "source": [
    "$P(A \\cap B) = P(A) \\cdot P(B)$\n",
    "\n",
    "Likewise, this can be extended to any number of intersections.<br>\n",
    "$P(A_1 \\cap A_2 \\cap \\dotsc \\cap A_n) = P(A_1) \\cdot P(A_2) \\cdot \\dotsc \\cdot P(A_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f74a74",
   "metadata": {},
   "source": [
    "**Inclusion-Exclusion Principle:**<br>\n",
    "In places where you have overlap between sets and probabilities are joint (such as pulling a jack or a spade from a deck of cards), its important to subtract the overlap as not to count it twice.\n",
    "\n",
    "$P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead8320",
   "metadata": {},
   "source": [
    "## Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92d56b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4b696a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4c0037d",
   "metadata": {},
   "source": [
    "## Baye's Theroem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec466c1",
   "metadata": {},
   "source": [
    "$ P (A|B) = P(A) \\frac{P(B|A)}{P(B)} $ or functionally $ P(H|E) = \\frac{P(H) \\cdot P(E|H)}{P(H) \\cdot P(E|H) + P(¬H) \\cdot P(E|¬H)} $\n",
    "\n",
    "Where $P(H)$ is your \"Prior\" or assumption and $P(¬H)$ is $1 - P(H)$.\n",
    "$P(E|H)$ is your \"Likelihood\"\n",
    "\n",
    "Or, $ Posterior = \\frac{Likelihood \\cdot Prior}{Evidence} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51940b39",
   "metadata": {},
   "source": [
    "### Multinomial Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7406a1b",
   "metadata": {},
   "source": [
    "$ \\large P(A|B_1 ,B_2, \\dotsc , B_n) = P(A) \\frac{P(B_1 |A) \\cdot P(B_2 |A) \\cdot  \\dotsc \\cdot P(B_n |A)}{P(B_1 ,B_2, \\dotsc , B_n)} $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
